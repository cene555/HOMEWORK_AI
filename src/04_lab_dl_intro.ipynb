{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9520d2",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4\n",
    "\n",
    "ФИО:   \n",
    "Группа: \n",
    "\n",
    "Отправлять можно следующими способами:\n",
    "1. Запушить этот ноутбук в GitHub в репозиторий, где у вас лежат ноутбуки с лабами\n",
    "\n",
    "Deadlines:\n",
    "- Занятие №7 в семестре\n",
    "\n",
    "Что необходимо сделать:  \n",
    "- Обучить различные модели глубокого обучения на имеющихся данных  \n",
    "\n",
    "---\n",
    "## Читайте задание внимательно\n",
    "\n",
    "Исходные данные:\n",
    "1. В [табличке](https://docs.google.com/spreadsheets/d/1NOE0D4JQgD6LbvUqWboUI1TFj4P87ugbqUTDquxlGEI/edit?usp=sharing) необходимо узнать название своего датасета \n",
    "2. Скачать нужны вам данные можно в [Google Drive](https://drive.google.com/drive/folders/1sbsjBsJ_ln0XgXCI9R6s17pvyvApgcwF?usp=sharing)\n",
    "  \n",
    "---\n",
    "Теперь по пунктам, что я от вас жду:  \n",
    "1. Загрузить необходимые данные к себе и считать (read) их в переменную.\n",
    "2. Понять, у вас задача классификации (бинарной или многоклассовой) или регрессии.\n",
    "3. Сделать предобработку данных:  \n",
    "     1. Разделить выборку на тренировочную (train) и тестовую (test). _Обратите внимание, что обучать скейлеры и определять, какими значениями вы будете заполнять пропуски, вы будете на train выборке, а применять и на train, и на test_.\n",
    "     2. Проверить пропуски в данных. Если они есть, заполнить одной из стратегий, предложенных в ноутбуке для семинара №3. P.S. Для численных и категориальных переменных будут разные стратегии.\n",
    "     3. Отнормировать численные переменные (`StandardScaler`, `MinMaxScaler`).\n",
    "     4. Закодировать категориальные признаки по одной из стратегий.\n",
    "4. Оформить данные в виде класса `Dataset` из библиотеки `torch` (как мы это делали на семинаре), а затем засунуть в `Dataloader` (тоже делали на семинаре).\n",
    "5. Обучить на тренировочном множестве:\n",
    "     1. Очень простую однослойную нейросеть с оптимизатором `SGD` ([link](https://pytorch.org/docs/stable/optim.html)).\n",
    "     2. Нейросеть посложнее (с 1 скрытым слоем) с оптимизатором `Adam` ([link](https://pytorch.org/docs/stable/optim.html)).\n",
    "     3. Нейросеть еще сложнее (с 3+ скрытыми слоями) с оптимизатором `Adam` ([link](https://pytorch.org/docs/stable/optim.html)).\n",
    "6. Посчитайте loss на train и test множествах, в зависимости от эпохи обучения. Провизуализируйте это с помощью библиотеки `matplotlib` (выйдет так называемая **learning curve**, кривая обучения модели).\n",
    "6. Посчитайте метрики на train и test множествах:\n",
    "     1. Для задачи классификации -- Accuracy\n",
    "     2. Для задачи регрессии -- MAE\n",
    "7. Сравните метрики относительно train/test, так и относительно разных моделей. Ответьте на следующие вопросы:\n",
    "     1. Какая модель справилась лучше с поставленной задачей?\n",
    "     2. Имеет ли место переобучение?\n",
    "     3. Имеет ли место недообучение?\n",
    "     4. Как можно улучшить метрики моделей?\n",
    "\n",
    "---\n",
    "P.S.  \n",
    "Просьба -- делать каждое задание в отдельных ячейках и с отдельными заголовками (как пункт 1 и 2 в этом ноутбуке) типа  \n",
    "- Заголовок\n",
    "- Ячейки с кодом\n",
    "- Другой заголовок\n",
    "- Другие ячейки с кодом\n",
    "\n",
    "P.S.S.  \n",
    "Если вам повезло с многоклассовой классификацией, у вас не будет проблем, просто нужно будет поставить необходимое количество нейронов на выходе вашей нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b51062",
   "metadata": {},
   "source": [
    "## 1. Пример импорта данных. Грузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406597a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/Users/cene/homework_ai/data/student-por.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d119028",
   "metadata": {},
   "source": [
    "## 2. Понимаем, какая перед нами задача"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92464d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nG3 - final grade (numeric: from 0 to 20, output target)\\nзначит, что можно сначала решить регрессией и классификацией, но регрессией будет лучше\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "G3 - final grade (numeric: from 0 to 20, output target)\n",
    "значит, что можно сначала решить регрессией и классификацией, но регрессией будет лучше\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34931f43",
   "metadata": {},
   "source": [
    "## 3. Делаем предобработку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a611d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data_object = data.select_dtypes(include = ['object'])\n",
    "\n",
    "impute = SimpleImputer(strategy = 'most_frequent')\n",
    "job = impute.fit_transform(data_object[['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
    "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
    "       'nursery', 'higher', 'internet', 'romantic']])\n",
    "\n",
    "job = pd.DataFrame(job)\n",
    "ohec = OneHotEncoder(sparse_output=False)\n",
    "ohec.fit_transform(job)\n",
    "ohec.categories_\n",
    "encoded_job = pd.DataFrame(ohec.fit_transform(job), columns=ohec.get_feature_names_out(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
    "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
    "       'nursery', 'higher', 'internet', 'romantic']))\n",
    "data_int = data.select_dtypes(include=['int64'])\n",
    "data_new = pd.concat([encoded_job, data_int], axis=1)\n",
    "X1 = data_new.drop(columns = ['G3', 'G1', 'G2'])\n",
    "y1 = data_new[\"G3\"]\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size =0.2, random_state=655) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d36f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X1_train)\n",
    "transformed_X1_train = scaler.transform(X1_train)\n",
    "transformed_X1_test = scaler.transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6cf276e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((519, 56), (519,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X1_train.shape, y1_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aacc1b",
   "metadata": {},
   "source": [
    "## 4. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb5f1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y.values)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45778557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(MyDataset(transformed_X1_train, y1_train), batch_size=4)\n",
    "test_dataloader = DataLoader(MyDataset(transformed_X1_test, y1_train), batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7b343",
   "metadata": {},
   "source": [
    "## 5 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7e69faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class MediumNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 4, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs=5, name=\"Model\"):\n",
    "    criterion = nn.L1Loss()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(epoch_loss / len(train_dataloader))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            for X_batch, y_batch in test_dataloader:\n",
    "                preds = model(X_batch)\n",
    "                test_loss += criterion(preds, y_batch).item()\n",
    "            test_losses.append(test_loss / len(test_dataloader))\n",
    "        \n",
    "        if (epoch+1) % 20 == 0:\n",
    "            print(f\"{name} | Epoch {epoch+1}/{epochs} | Train MAE: {train_losses[-1]:.4f} | Test MAE: {test_losses[-1]:.4f}\")\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31adcb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаем SimpleNet (SGD)...\n",
      "SimpleNet (SGD) | Epoch 20/100 | Train MAE: 2.3933 | Test MAE: 2.7239\n",
      "SimpleNet (SGD) | Epoch 40/100 | Train MAE: 2.3903 | Test MAE: 2.7467\n",
      "SimpleNet (SGD) | Epoch 60/100 | Train MAE: 2.3906 | Test MAE: 2.7507\n",
      "SimpleNet (SGD) | Epoch 80/100 | Train MAE: 2.3909 | Test MAE: 2.7512\n",
      "SimpleNet (SGD) | Epoch 100/100 | Train MAE: 2.3907 | Test MAE: 2.7486\n",
      "\n",
      "Обучаем MediumNet (Adam)...\n",
      "MediumNet (Adam) | Epoch 20/150 | Train MAE: 2.3497 | Test MAE: 3.2075\n",
      "MediumNet (Adam) | Epoch 40/150 | Train MAE: 2.2945 | Test MAE: 3.0770\n",
      "MediumNet (Adam) | Epoch 60/150 | Train MAE: 2.2427 | Test MAE: 3.2625\n",
      "MediumNet (Adam) | Epoch 80/150 | Train MAE: 2.2017 | Test MAE: 3.1149\n",
      "MediumNet (Adam) | Epoch 100/150 | Train MAE: 2.2126 | Test MAE: 2.9511\n",
      "MediumNet (Adam) | Epoch 120/150 | Train MAE: 2.1896 | Test MAE: 2.9686\n",
      "MediumNet (Adam) | Epoch 140/150 | Train MAE: 2.1639 | Test MAE: 2.9393\n",
      "\n",
      "Обучаем DeepNet (Adam)...\n",
      "DeepNet (Adam) | Epoch 20/200 | Train MAE: 2.4851 | Test MAE: 3.2207\n",
      "DeepNet (Adam) | Epoch 40/200 | Train MAE: 2.3344 | Test MAE: 2.9279\n",
      "DeepNet (Adam) | Epoch 60/200 | Train MAE: 2.3038 | Test MAE: 3.0894\n",
      "DeepNet (Adam) | Epoch 80/200 | Train MAE: 2.2366 | Test MAE: 2.8533\n",
      "DeepNet (Adam) | Epoch 100/200 | Train MAE: 2.2290 | Test MAE: 3.1021\n",
      "DeepNet (Adam) | Epoch 120/200 | Train MAE: 2.1878 | Test MAE: 3.0678\n",
      "DeepNet (Adam) | Epoch 140/200 | Train MAE: 2.1800 | Test MAE: 3.0112\n",
      "DeepNet (Adam) | Epoch 160/200 | Train MAE: 2.1811 | Test MAE: 3.0215\n",
      "DeepNet (Adam) | Epoch 180/200 | Train MAE: 2.1708 | Test MAE: 2.8313\n",
      "DeepNet (Adam) | Epoch 200/200 | Train MAE: 2.1628 | Test MAE: 2.9671\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "input_size = transformed_X1_train.shape[1]\n",
    "\n",
    "model1 = SimpleNet(input_size)\n",
    "opt1 = optim.SGD(model1.parameters(), lr=0.01)\n",
    "print(\"Обучаем SimpleNet (SGD)...\")\n",
    "train1, test1 = train_model(model1, opt1, epochs=100, name=\"SimpleNet (SGD)\")\n",
    "\n",
    "model2 = MediumNet(input_size)\n",
    "opt2 = optim.Adam(model2.parameters(), lr=0.01)\n",
    "print(\"\\nОбучаем MediumNet (Adam)...\")\n",
    "train2, test2 = train_model(model2, opt2, epochs=150, name=\"MediumNet (Adam)\")\n",
    "\n",
    "model3 = DeepNet(input_size)\n",
    "opt3 = optim.Adam(model3.parameters(), lr=0.003)\n",
    "print(\"\\nОбучаем DeepNet (Adam)...\")\n",
    "train3, test3 = train_model(model3, opt3, epochs=200, name=\"DeepNet (Adam)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# лучше всего спраивлась маленькая сетка"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
